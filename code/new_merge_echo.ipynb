{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new data\n",
    "# read each page from excel file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename='cleaned'\n",
    "Pacific=pd.read_excel(filename+'.xlsx',sheet_name='Pacific')\n",
    "Atlantic=pd.read_excel(filename+'.xlsx',sheet_name='Atlantic')\n",
    "Mediterranean=pd.read_excel(filename+'.xlsx',sheet_name='Mediterranean')\n",
    "Southern=pd.read_excel(filename+'.xlsx',sheet_name='Southern Ocean')\n",
    "Arctic=pd.read_excel(filename+'.xlsx',sheet_name='Arctic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df2 = Pacific[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df2['Lat'] = df2['Lat'].astype(str)\n",
    "df2['Long'] = df2['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df2['Lat'] = df2['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df2['Long'] = df2['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df2 = df2.dropna(subset=['Lat','Long'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import gzip\n",
    "from pyhdf.SD import SD, SDC\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df2['Lat'].copy()\n",
    "orig_lons = df2['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/vgpm.s.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'npp' dataset\n",
    "                        data = hdf_file.select('npp')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df2['Lat'], df2['Long'])))\n",
    "                        df2[f'npp_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df2['Year'] = year\n",
    "        df2['Lat'] = orig_lats\n",
    "        df2['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df2])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('npp_means_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_npp'] = all_results.filter(regex='npp_').mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data csv\n",
    "all_results.to_csv('npp_means_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the data\n",
    "\n",
    "\n",
    "df_npp_means = pd.read_csv('npp_means_new.csv')\n",
    "df_npp_means.sample(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
