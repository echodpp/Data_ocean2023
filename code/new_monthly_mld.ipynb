{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new data\n",
    "# read each page from excel file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filename='cleaned'\n",
    "Pacific=pd.read_excel(filename+'.xlsx',sheet_name='Pacific')\n",
    "Atlantic=pd.read_excel(filename+'.xlsx',sheet_name='Atlantic')\n",
    "Mediterranean=pd.read_excel(filename+'.xlsx',sheet_name='Mediterranean')\n",
    "Southern=pd.read_excel(filename+'.xlsx',sheet_name='Southern Ocean')\n",
    "Arctic=pd.read_excel(filename+'.xlsx',sheet_name='Arctic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-e6a624ea674d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Lat'] = df2['Lat'].astype(str)\n",
      "<ipython-input-23-e6a624ea674d>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Long'] = df2['Long'].astype(str)\n",
      "<ipython-input-23-e6a624ea674d>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Lat'] = df2['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
      "<ipython-input-23-e6a624ea674d>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Long'] = df2['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df2 = Pacific[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df2['Lat'] = df2['Lat'].astype(str)\n",
    "df2['Long'] = df2['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df2['Lat'] = df2['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df2['Long'] = df2['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df2 = df2.dropna(subset=['Lat','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import gzip\n",
    "\n",
    "from pyhdf.SD import SD, SDC\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df2['Lat'].copy()\n",
    "orig_lons = df2['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/mld.hycom_030.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'mld' dataset\n",
    "                        data = hdf_file.select('mld')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df2['Lat'], df2['Long'])))\n",
    "                        df2[f'mld_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df2['Year'] = year\n",
    "        df2['Lat'] = orig_lats\n",
    "        df2['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df2])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('mld_means_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_mld'] = all_results.filter(regex='mld_').mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of Cr_nmol/kg from the 'cleaned' excel file\n",
    "all_results['Cr_nmol/kg'] = Pacific['Cr_nmol/kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 'Ocean' column filled with \"Pacific\" to the df_ocean_processed DataFrame\n",
    "all_results['Ocean'] = 'Pacific'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data csv\n",
    "all_results.to_csv('mld_means_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Year</th>\n",
       "      <th>mld_09</th>\n",
       "      <th>mld_10</th>\n",
       "      <th>mld_11</th>\n",
       "      <th>mld_12</th>\n",
       "      <th>mld_01</th>\n",
       "      <th>mld_02</th>\n",
       "      <th>mld_04</th>\n",
       "      <th>mld_05</th>\n",
       "      <th>mld_06</th>\n",
       "      <th>mld_07</th>\n",
       "      <th>mld_08</th>\n",
       "      <th>mld_03</th>\n",
       "      <th>yearly_mean_mld</th>\n",
       "      <th>Cr_nmol/kg</th>\n",
       "      <th>Ocean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11799</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>-132.000000</td>\n",
       "      <td>2019</td>\n",
       "      <td>35.773823</td>\n",
       "      <td>44.033195</td>\n",
       "      <td>54.647850</td>\n",
       "      <td>61.697723</td>\n",
       "      <td>65.464615</td>\n",
       "      <td>39.998505</td>\n",
       "      <td>37.391120</td>\n",
       "      <td>24.333548</td>\n",
       "      <td>28.156792</td>\n",
       "      <td>32.953600</td>\n",
       "      <td>42.110462</td>\n",
       "      <td>45.117050</td>\n",
       "      <td>42.639860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>-145.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>17.160799</td>\n",
       "      <td>29.502502</td>\n",
       "      <td>45.377365</td>\n",
       "      <td>55.758110</td>\n",
       "      <td>62.890617</td>\n",
       "      <td>71.293230</td>\n",
       "      <td>51.501812</td>\n",
       "      <td>31.589933</td>\n",
       "      <td>21.348188</td>\n",
       "      <td>19.492756</td>\n",
       "      <td>15.737129</td>\n",
       "      <td>73.341610</td>\n",
       "      <td>41.249500</td>\n",
       "      <td>3.853659</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-79.845000</td>\n",
       "      <td>2002</td>\n",
       "      <td>27.087984</td>\n",
       "      <td>24.019594</td>\n",
       "      <td>16.052288</td>\n",
       "      <td>15.315970</td>\n",
       "      <td>12.984103</td>\n",
       "      <td>11.577427</td>\n",
       "      <td>13.890297</td>\n",
       "      <td>17.621280</td>\n",
       "      <td>23.316814</td>\n",
       "      <td>36.388794</td>\n",
       "      <td>33.158220</td>\n",
       "      <td>11.862844</td>\n",
       "      <td>20.272968</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>-12.010000</td>\n",
       "      <td>-79.200000</td>\n",
       "      <td>1998</td>\n",
       "      <td>30.703670</td>\n",
       "      <td>22.395218</td>\n",
       "      <td>17.953556</td>\n",
       "      <td>16.041576</td>\n",
       "      <td>18.049812</td>\n",
       "      <td>18.394129</td>\n",
       "      <td>19.967012</td>\n",
       "      <td>28.251144</td>\n",
       "      <td>45.978848</td>\n",
       "      <td>36.421505</td>\n",
       "      <td>39.396206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.686607</td>\n",
       "      <td>3.460183</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10811</th>\n",
       "      <td>24.283333</td>\n",
       "      <td>-114.983333</td>\n",
       "      <td>2017</td>\n",
       "      <td>14.572323</td>\n",
       "      <td>14.941182</td>\n",
       "      <td>16.498848</td>\n",
       "      <td>23.960426</td>\n",
       "      <td>33.799854</td>\n",
       "      <td>26.152592</td>\n",
       "      <td>24.388525</td>\n",
       "      <td>21.035969</td>\n",
       "      <td>17.936180</td>\n",
       "      <td>12.862591</td>\n",
       "      <td>15.503565</td>\n",
       "      <td>22.272566</td>\n",
       "      <td>20.327051</td>\n",
       "      <td>4.355481</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8563</th>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>62.235670</td>\n",
       "      <td>32.146027</td>\n",
       "      <td>42.556213</td>\n",
       "      <td>37.028057</td>\n",
       "      <td>23.676428</td>\n",
       "      <td>23.933200</td>\n",
       "      <td>28.135052</td>\n",
       "      <td>33.344200</td>\n",
       "      <td>31.751907</td>\n",
       "      <td>42.561295</td>\n",
       "      <td>54.609653</td>\n",
       "      <td>24.496094</td>\n",
       "      <td>36.372814</td>\n",
       "      <td>3.008331</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>33.906470</td>\n",
       "      <td>44.592820</td>\n",
       "      <td>52.376740</td>\n",
       "      <td>27.468456</td>\n",
       "      <td>20.946709</td>\n",
       "      <td>24.963343</td>\n",
       "      <td>28.529898</td>\n",
       "      <td>29.470053</td>\n",
       "      <td>49.714134</td>\n",
       "      <td>46.478638</td>\n",
       "      <td>47.438572</td>\n",
       "      <td>24.496094</td>\n",
       "      <td>35.865160</td>\n",
       "      <td>4.851725</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>-3.583000</td>\n",
       "      <td>-85.833000</td>\n",
       "      <td>2005</td>\n",
       "      <td>28.474422</td>\n",
       "      <td>30.479767</td>\n",
       "      <td>20.338902</td>\n",
       "      <td>12.629570</td>\n",
       "      <td>11.993477</td>\n",
       "      <td>11.764564</td>\n",
       "      <td>19.533653</td>\n",
       "      <td>19.734050</td>\n",
       "      <td>24.645233</td>\n",
       "      <td>33.642160</td>\n",
       "      <td>27.701319</td>\n",
       "      <td>12.181180</td>\n",
       "      <td>21.093193</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10181</th>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>33.906470</td>\n",
       "      <td>44.592820</td>\n",
       "      <td>52.376740</td>\n",
       "      <td>27.468456</td>\n",
       "      <td>20.946709</td>\n",
       "      <td>24.963343</td>\n",
       "      <td>28.529898</td>\n",
       "      <td>29.470053</td>\n",
       "      <td>49.714134</td>\n",
       "      <td>46.478638</td>\n",
       "      <td>47.438572</td>\n",
       "      <td>24.496094</td>\n",
       "      <td>35.865160</td>\n",
       "      <td>5.088152</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>-34.670000</td>\n",
       "      <td>154.550000</td>\n",
       "      <td>2013</td>\n",
       "      <td>43.255870</td>\n",
       "      <td>44.462242</td>\n",
       "      <td>59.141174</td>\n",
       "      <td>33.416084</td>\n",
       "      <td>44.395340</td>\n",
       "      <td>46.464250</td>\n",
       "      <td>71.151460</td>\n",
       "      <td>71.964620</td>\n",
       "      <td>66.751560</td>\n",
       "      <td>63.897453</td>\n",
       "      <td>77.528030</td>\n",
       "      <td>52.580505</td>\n",
       "      <td>56.250713</td>\n",
       "      <td>3.027112</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lat        Long  Year     mld_09     mld_10     mld_11  \\\n",
       "11799  21.000000 -132.000000  2019  35.773823  44.033195  54.647850   \n",
       "10350  50.000000 -145.000000  2016  17.160799  29.502502  45.377365   \n",
       "3013   -8.000000  -79.845000  2002  27.087984  24.019594  16.052288   \n",
       "1022  -12.010000  -79.200000  1998  30.703670  22.395218  17.953556   \n",
       "10811  24.283333 -114.983333  2017  14.572323  14.941182  16.498848   \n",
       "8563  -14.000000  -99.000000  2012  62.235670  32.146027  42.556213   \n",
       "10179 -14.000000  -99.000000  2015  33.906470  44.592820  52.376740   \n",
       "4618   -3.583000  -85.833000  2005  28.474422  30.479767  20.338902   \n",
       "10181 -14.000000  -99.000000  2015  33.906470  44.592820  52.376740   \n",
       "9027  -34.670000  154.550000  2013  43.255870  44.462242  59.141174   \n",
       "\n",
       "          mld_12     mld_01     mld_02     mld_04     mld_05     mld_06  \\\n",
       "11799  61.697723  65.464615  39.998505  37.391120  24.333548  28.156792   \n",
       "10350  55.758110  62.890617  71.293230  51.501812  31.589933  21.348188   \n",
       "3013   15.315970  12.984103  11.577427  13.890297  17.621280  23.316814   \n",
       "1022   16.041576  18.049812  18.394129  19.967012  28.251144  45.978848   \n",
       "10811  23.960426  33.799854  26.152592  24.388525  21.035969  17.936180   \n",
       "8563   37.028057  23.676428  23.933200  28.135052  33.344200  31.751907   \n",
       "10179  27.468456  20.946709  24.963343  28.529898  29.470053  49.714134   \n",
       "4618   12.629570  11.993477  11.764564  19.533653  19.734050  24.645233   \n",
       "10181  27.468456  20.946709  24.963343  28.529898  29.470053  49.714134   \n",
       "9027   33.416084  44.395340  46.464250  71.151460  71.964620  66.751560   \n",
       "\n",
       "          mld_07     mld_08     mld_03  yearly_mean_mld  Cr_nmol/kg    Ocean  \n",
       "11799  32.953600  42.110462  45.117050        42.639860         NaN  Pacific  \n",
       "10350  19.492756  15.737129  73.341610        41.249500    3.853659  Pacific  \n",
       "3013   36.388794  33.158220  11.862844        20.272968    1.500000  Pacific  \n",
       "1022   36.421505  39.396206        NaN        26.686607    3.460183  Pacific  \n",
       "10811  12.862591  15.503565  22.272566        20.327051    4.355481  Pacific  \n",
       "8563   42.561295  54.609653  24.496094        36.372814    3.008331  Pacific  \n",
       "10179  46.478638  47.438572  24.496094        35.865160    4.851725  Pacific  \n",
       "4618   33.642160  27.701319  12.181180        21.093193    5.290000  Pacific  \n",
       "10181  46.478638  47.438572  24.496094        35.865160    5.088152  Pacific  \n",
       "9027   63.897453  77.528030  52.580505        56.250713    3.027112  Pacific  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "df_mld_means = pd.read_csv('mld_means_1.csv')\n",
    "df_mld_means.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-a2adcc3e5c57>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Lat'] = df3['Lat'].astype(str)\n",
      "<ipython-input-30-a2adcc3e5c57>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Long'] = df3['Long'].astype(str)\n",
      "<ipython-input-30-a2adcc3e5c57>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Lat'] = df3['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
      "<ipython-input-30-a2adcc3e5c57>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Long'] = df3['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df3 = Atlantic[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df3['Lat'] = df3['Lat'].astype(str)\n",
    "df3['Long'] = df3['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df3['Lat'] = df3['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df3['Long'] = df3['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df3 = df3.dropna(subset=['Lat','Long'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import gzip\n",
    "from pyhdf.SD import SD, SDC\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df3['Lat'].copy()\n",
    "orig_lons = df3['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/mld.hycom_030.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'npp' dataset\n",
    "                        data = hdf_file.select('mld')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df3['Lat'], df3['Long'])))\n",
    "                        df3[f'mld_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df3['Year'] = year\n",
    "        df3['Lat'] = orig_lats\n",
    "        df3['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df3])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('mld_means_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_mld'] = all_results.filter(regex='mld_').mean(axis=1)\n",
    "# add a column of Cr_nmol/kg from the 'cleaned' excel file\n",
    "all_results['Cr_nmol/kg'] = Atlantic['Cr_nmol/kg']\n",
    "# create the 'Ocean' column filled with \"Pacific\" to the df_ocean_processed DataFrame\n",
    "all_results['Ocean'] = 'Atlantic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data csv\n",
    "all_results.to_csv('mld_means_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-aacb700961e0>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Lat'] = df4['Lat'].astype(str)\n",
      "<ipython-input-34-aacb700961e0>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Long'] = df4['Long'].astype(str)\n",
      "<ipython-input-34-aacb700961e0>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Lat'] = df4['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
      "<ipython-input-34-aacb700961e0>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4['Long'] = df4['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df4 = Mediterranean[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df4['Lat'] = df4['Lat'].astype(str)\n",
    "df4['Long'] = df4['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df4['Lat'] = df4['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df4['Long'] = df4['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df4 = df4.dropna(subset=['Lat','Long'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df4['Lat'].copy()\n",
    "orig_lons = df4['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/mld.hycom_030.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'npp' dataset\n",
    "                        data = hdf_file.select('mld')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df4['Lat'], df4['Long'])))\n",
    "                        df4[f'mld_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df4['Year'] = year\n",
    "        df4['Lat'] = orig_lats\n",
    "        df4['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df4])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('mld_means_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_mld'] = all_results.filter(regex='mld_').mean(axis=1)\n",
    "# add a column of Cr_nmol/kg from the 'cleaned' excel file\n",
    "all_results['Cr_nmol/kg'] = Mediterranean['Cr_nmol/kg']\n",
    "# create the 'Ocean' column filled with \"Pacific\" to the df_ocean_processed DataFrame\n",
    "all_results['Ocean'] = 'Mediterranean'\n",
    "# save the data csv\n",
    "all_results.to_csv('mld_means_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ba7fc8eba4aa>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5['Lat'] = df5['Lat'].astype(str)\n",
      "<ipython-input-37-ba7fc8eba4aa>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5['Long'] = df5['Long'].astype(str)\n",
      "<ipython-input-37-ba7fc8eba4aa>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5['Lat'] = df5['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
      "<ipython-input-37-ba7fc8eba4aa>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df5['Long'] = df5['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df5 = Southern[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df5['Lat'] = df5['Lat'].astype(str)\n",
    "df5['Long'] = df5['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df5['Lat'] = df5['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df5['Long'] = df5['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df5 = df5.dropna(subset=['Lat','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df5['Lat'].copy()\n",
    "orig_lons = df5['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/mld.hycom_030.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'npp' dataset\n",
    "                        data = hdf_file.select('mld')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df5['Lat'], df5['Long'])))\n",
    "                        df5[f'mld_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df5['Year'] = year\n",
    "        df5['Lat'] = orig_lats\n",
    "        df5['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df5])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('mld_means_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_mld'] = all_results.filter(regex='mld_').mean(axis=1)\n",
    "# add a column of Cr_nmol/kg from the 'cleaned' excel file\n",
    "all_results['Cr_nmol/kg'] = Southern['Cr_nmol/kg']\n",
    "# create the 'Ocean' column filled with \"Pacific\" to the df_ocean_processed DataFrame\n",
    "all_results['Ocean'] = 'Southern'\n",
    "# save the data csv\n",
    "all_results.to_csv('mld_means_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-49ca953795be>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df6['Lat'] = df6['Lat'].astype(str)\n",
      "<ipython-input-40-49ca953795be>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df6['Long'] = df6['Long'].astype(str)\n",
      "<ipython-input-40-49ca953795be>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df6['Lat'] = df6['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
      "<ipython-input-40-49ca953795be>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df6['Long'] = df6['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# we will be only merge one ocean at a time \n",
    "\n",
    "df6 = Arctic[['Lat','Long','Year']]\n",
    "# convert to 'Lat','Long' string \n",
    "df6['Lat'] = df6['Lat'].astype(str)\n",
    "df6['Long'] = df6['Long'].astype(str)\n",
    "\n",
    "# here shockingly we have chinese character in the data!\n",
    "df6['Lat'] = df6['Lat'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "df6['Long'] = df6['Long'].apply(lambda x: x.replace('−', '-')).astype(float)\n",
    "# drop nan in lat and long \n",
    "df6 = df6.dropna(subset=['Lat','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the years\n",
    "years = range(1997, 2024)\n",
    "\n",
    "# Empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Get the original latitudes and longitudes\n",
    "orig_lats = df6['Lat'].copy()\n",
    "orig_lons = df6['Long'].copy()\n",
    "\n",
    "for year in years:\n",
    "    with tarfile.open(f'data/mld.hycom_030.{year}.tar', \"r:\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('.hdf.gz'):\n",
    "                # Decide month from the filename=day of year\n",
    "                # last three integers\n",
    "                day_of_year = int(str(member.name.split('.')[1])[-3:])\n",
    "                month = str((day_of_year - 1) // 30 + 1).zfill(2)\n",
    "\n",
    "                # Open the .hdf.gz file\n",
    "                f = tar.extractfile(member)\n",
    "                with gzip.open(f, 'rb') as gz:\n",
    "                    # Decompress the .hdf.gz file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile() as tmp:\n",
    "                        tmp.write(gz.read())\n",
    "                        tmp.seek(0)  # Go back to the start of the file\n",
    "\n",
    "                        # Open the temporary .hdf file\n",
    "                        hdf_file = SD(tmp.name, SDC.READ)\n",
    "                        # Access the 'npp' dataset\n",
    "                        data = hdf_file.select('mld')[:]\n",
    "\n",
    "                        # Replace '-9999.0' with NaN\n",
    "                        data[data == -9999.0] = np.nan\n",
    "\n",
    "                        # Define the latitude and longitude arrays\n",
    "                        lats = np.linspace(90, -90, data.shape[0])  # Shape[0] is the number of rows\n",
    "                        lons = np.linspace(-180, 180, data.shape[1])  # Shape[1] is the number of columns\n",
    "\n",
    "                        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "                        lat_list = lat_grid.reshape(-1,1)\n",
    "                        lon_list = lon_grid.reshape(-1,1)\n",
    "                        points = np.concatenate([lat_list, lon_list], axis=1)\n",
    "                        xi = np.array(list(zip(df6['Lat'], df6['Long'])))\n",
    "                        df6[f'mld_{month}'] = griddata(points, data.ravel(), xi, method='nearest')\n",
    "\n",
    "        # Add the year column\n",
    "        df6['Year'] = year\n",
    "        df6['Lat'] = orig_lats\n",
    "        df6['Long'] = orig_lons\n",
    "\n",
    "        # Append df2 to the results DataFrame\n",
    "        all_results = pd.concat([all_results, df6])\n",
    "\n",
    "    # Close the file\n",
    "    hdf_file.end()\n",
    "\n",
    "# save the data\n",
    "all_results.to_csv('mld_means_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of yearly mean\n",
    "all_results['yearly_mean_mld'] = all_results.filter(regex='mld_').mean(axis=1)\n",
    "# add a column of Cr_nmol/kg from the 'cleaned' excel file\n",
    "all_results['Cr_nmol/kg'] = Arctic['Cr_nmol/kg']\n",
    "# create the 'Ocean' column filled with \"Pacific\" to the df_ocean_processed DataFrame\n",
    "all_results['Ocean'] = 'Arctic'\n",
    "# save the data csv\n",
    "all_results.to_csv('mld_means_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = pd.read_csv('mld_means_1.csv')\n",
    "dt2 = pd.read_csv('mld_means_2.csv')\n",
    "dt3 = pd.read_csv('mld_means_3.csv')\n",
    "dt4 = pd.read_csv('mld_means_4.csv')\n",
    "dt5 = pd.read_csv('mld_means_5.csv')\n",
    "merged_df = pd.concat([dt1, dt2, dt3, dt4, dt5])\n",
    "merged_df.to_csv('mld_means_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Year</th>\n",
       "      <th>mld_09</th>\n",
       "      <th>mld_10</th>\n",
       "      <th>mld_11</th>\n",
       "      <th>mld_12</th>\n",
       "      <th>mld_01</th>\n",
       "      <th>mld_02</th>\n",
       "      <th>mld_04</th>\n",
       "      <th>mld_05</th>\n",
       "      <th>mld_06</th>\n",
       "      <th>mld_07</th>\n",
       "      <th>mld_08</th>\n",
       "      <th>mld_03</th>\n",
       "      <th>yearly_mean_mld</th>\n",
       "      <th>Cr_nmol/kg</th>\n",
       "      <th>Ocean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>-9.999000</td>\n",
       "      <td>-79.134000</td>\n",
       "      <td>2012</td>\n",
       "      <td>21.604820</td>\n",
       "      <td>23.027210</td>\n",
       "      <td>18.861963</td>\n",
       "      <td>12.547065</td>\n",
       "      <td>13.067307</td>\n",
       "      <td>13.217509</td>\n",
       "      <td>16.491669</td>\n",
       "      <td>21.407473</td>\n",
       "      <td>23.174011</td>\n",
       "      <td>28.038462</td>\n",
       "      <td>24.560125</td>\n",
       "      <td>15.555095</td>\n",
       "      <td>19.296060</td>\n",
       "      <td>2.530000</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23948</th>\n",
       "      <td>-46.970000</td>\n",
       "      <td>141.930000</td>\n",
       "      <td>1999</td>\n",
       "      <td>103.057280</td>\n",
       "      <td>102.950455</td>\n",
       "      <td>87.721840</td>\n",
       "      <td>58.018356</td>\n",
       "      <td>51.132977</td>\n",
       "      <td>68.318474</td>\n",
       "      <td>98.596146</td>\n",
       "      <td>106.240220</td>\n",
       "      <td>98.213120</td>\n",
       "      <td>118.885390</td>\n",
       "      <td>134.858380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.453880</td>\n",
       "      <td>2.880965</td>\n",
       "      <td>Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13442</th>\n",
       "      <td>21.476667</td>\n",
       "      <td>-126.595000</td>\n",
       "      <td>2022</td>\n",
       "      <td>25.172592</td>\n",
       "      <td>32.326077</td>\n",
       "      <td>53.720116</td>\n",
       "      <td>70.297440</td>\n",
       "      <td>47.489070</td>\n",
       "      <td>46.780205</td>\n",
       "      <td>49.123300</td>\n",
       "      <td>38.048140</td>\n",
       "      <td>31.922838</td>\n",
       "      <td>27.018564</td>\n",
       "      <td>23.418705</td>\n",
       "      <td>35.157295</td>\n",
       "      <td>40.039524</td>\n",
       "      <td>4.034170</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17138</th>\n",
       "      <td>47.243400</td>\n",
       "      <td>-9.331883</td>\n",
       "      <td>2005</td>\n",
       "      <td>28.482086</td>\n",
       "      <td>40.281395</td>\n",
       "      <td>69.153090</td>\n",
       "      <td>83.286580</td>\n",
       "      <td>152.804170</td>\n",
       "      <td>140.035580</td>\n",
       "      <td>42.953247</td>\n",
       "      <td>23.801641</td>\n",
       "      <td>15.054678</td>\n",
       "      <td>17.181686</td>\n",
       "      <td>18.275131</td>\n",
       "      <td>200.220250</td>\n",
       "      <td>69.294130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>-21.566667</td>\n",
       "      <td>-114.300000</td>\n",
       "      <td>2016</td>\n",
       "      <td>45.339752</td>\n",
       "      <td>22.453900</td>\n",
       "      <td>27.899988</td>\n",
       "      <td>22.177624</td>\n",
       "      <td>18.796390</td>\n",
       "      <td>24.617613</td>\n",
       "      <td>35.492325</td>\n",
       "      <td>42.559220</td>\n",
       "      <td>53.015453</td>\n",
       "      <td>54.544920</td>\n",
       "      <td>45.253880</td>\n",
       "      <td>31.760994</td>\n",
       "      <td>35.326004</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>24.283333</td>\n",
       "      <td>-114.983333</td>\n",
       "      <td>2001</td>\n",
       "      <td>16.164707</td>\n",
       "      <td>21.872047</td>\n",
       "      <td>29.897419</td>\n",
       "      <td>35.636340</td>\n",
       "      <td>41.395610</td>\n",
       "      <td>32.337494</td>\n",
       "      <td>25.542423</td>\n",
       "      <td>26.592655</td>\n",
       "      <td>19.512148</td>\n",
       "      <td>13.433430</td>\n",
       "      <td>13.389800</td>\n",
       "      <td>31.833996</td>\n",
       "      <td>25.634005</td>\n",
       "      <td>2.471071</td>\n",
       "      <td>Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>-2.962500</td>\n",
       "      <td>-25.614800</td>\n",
       "      <td>2010</td>\n",
       "      <td>54.603466</td>\n",
       "      <td>40.785103</td>\n",
       "      <td>52.917484</td>\n",
       "      <td>39.502914</td>\n",
       "      <td>28.011198</td>\n",
       "      <td>32.757680</td>\n",
       "      <td>31.228874</td>\n",
       "      <td>32.537100</td>\n",
       "      <td>39.552456</td>\n",
       "      <td>49.912037</td>\n",
       "      <td>49.075850</td>\n",
       "      <td>35.774060</td>\n",
       "      <td>40.554850</td>\n",
       "      <td>2.709797</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26919</th>\n",
       "      <td>-53.583000</td>\n",
       "      <td>149.298000</td>\n",
       "      <td>2020</td>\n",
       "      <td>117.081860</td>\n",
       "      <td>124.322000</td>\n",
       "      <td>66.848570</td>\n",
       "      <td>54.147810</td>\n",
       "      <td>43.221714</td>\n",
       "      <td>51.402130</td>\n",
       "      <td>63.646240</td>\n",
       "      <td>82.055695</td>\n",
       "      <td>93.573060</td>\n",
       "      <td>97.394135</td>\n",
       "      <td>93.803894</td>\n",
       "      <td>61.848656</td>\n",
       "      <td>79.112144</td>\n",
       "      <td>3.758093</td>\n",
       "      <td>Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25136</th>\n",
       "      <td>-47.000000</td>\n",
       "      <td>141.900000</td>\n",
       "      <td>2007</td>\n",
       "      <td>162.623870</td>\n",
       "      <td>173.892870</td>\n",
       "      <td>97.866714</td>\n",
       "      <td>60.285126</td>\n",
       "      <td>42.603065</td>\n",
       "      <td>60.025870</td>\n",
       "      <td>63.591633</td>\n",
       "      <td>73.241970</td>\n",
       "      <td>118.419970</td>\n",
       "      <td>122.544014</td>\n",
       "      <td>159.943240</td>\n",
       "      <td>74.493140</td>\n",
       "      <td>100.794290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>12.743667</td>\n",
       "      <td>-28.501500</td>\n",
       "      <td>2004</td>\n",
       "      <td>14.589371</td>\n",
       "      <td>17.886166</td>\n",
       "      <td>15.857555</td>\n",
       "      <td>36.326126</td>\n",
       "      <td>44.873096</td>\n",
       "      <td>38.656600</td>\n",
       "      <td>34.757305</td>\n",
       "      <td>32.137444</td>\n",
       "      <td>25.819876</td>\n",
       "      <td>14.680635</td>\n",
       "      <td>16.787842</td>\n",
       "      <td>33.814102</td>\n",
       "      <td>27.182180</td>\n",
       "      <td>2.930142</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lat        Long  Year      mld_09      mld_10     mld_11  \\\n",
       "8377   -9.999000  -79.134000  2012   21.604820   23.027210  18.861963   \n",
       "23948 -46.970000  141.930000  1999  103.057280  102.950455  87.721840   \n",
       "13442  21.476667 -126.595000  2022   25.172592   32.326077  53.720116   \n",
       "17138  47.243400   -9.331883  2005   28.482086   40.281395  69.153090   \n",
       "10320 -21.566667 -114.300000  2016   45.339752   22.453900  27.899988   \n",
       "2213   24.283333 -114.983333  2001   16.164707   21.872047  29.897419   \n",
       "18652  -2.962500  -25.614800  2010   54.603466   40.785103  52.917484   \n",
       "26919 -53.583000  149.298000  2020  117.081860  124.322000  66.848570   \n",
       "25136 -47.000000  141.900000  2007  162.623870  173.892870  97.866714   \n",
       "16874  12.743667  -28.501500  2004   14.589371   17.886166  15.857555   \n",
       "\n",
       "          mld_12      mld_01      mld_02     mld_04      mld_05      mld_06  \\\n",
       "8377   12.547065   13.067307   13.217509  16.491669   21.407473   23.174011   \n",
       "23948  58.018356   51.132977   68.318474  98.596146  106.240220   98.213120   \n",
       "13442  70.297440   47.489070   46.780205  49.123300   38.048140   31.922838   \n",
       "17138  83.286580  152.804170  140.035580  42.953247   23.801641   15.054678   \n",
       "10320  22.177624   18.796390   24.617613  35.492325   42.559220   53.015453   \n",
       "2213   35.636340   41.395610   32.337494  25.542423   26.592655   19.512148   \n",
       "18652  39.502914   28.011198   32.757680  31.228874   32.537100   39.552456   \n",
       "26919  54.147810   43.221714   51.402130  63.646240   82.055695   93.573060   \n",
       "25136  60.285126   42.603065   60.025870  63.591633   73.241970  118.419970   \n",
       "16874  36.326126   44.873096   38.656600  34.757305   32.137444   25.819876   \n",
       "\n",
       "           mld_07      mld_08      mld_03  yearly_mean_mld  Cr_nmol/kg  \\\n",
       "8377    28.038462   24.560125   15.555095        19.296060    2.530000   \n",
       "23948  118.885390  134.858380         NaN        93.453880    2.880965   \n",
       "13442   27.018564   23.418705   35.157295        40.039524    4.034170   \n",
       "17138   17.181686   18.275131  200.220250        69.294130         NaN   \n",
       "10320   54.544920   45.253880   31.760994        35.326004    6.500000   \n",
       "2213    13.433430   13.389800   31.833996        25.634005    2.471071   \n",
       "18652   49.912037   49.075850   35.774060        40.554850    2.709797   \n",
       "26919   97.394135   93.803894   61.848656        79.112144    3.758093   \n",
       "25136  122.544014  159.943240   74.493140       100.794290         NaN   \n",
       "16874   14.680635   16.787842   33.814102        27.182180    2.930142   \n",
       "\n",
       "          Ocean  \n",
       "8377    Pacific  \n",
       "23948  Southern  \n",
       "13442   Pacific  \n",
       "17138  Atlantic  \n",
       "10320   Pacific  \n",
       "2213    Pacific  \n",
       "18652  Atlantic  \n",
       "26919  Southern  \n",
       "25136  Southern  \n",
       "16874  Atlantic  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "df_mld_means = pd.read_csv('mld_means_new.csv')\n",
    "df_mld_means.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
